# 可靠性

我们已经看到提示词技巧可以让大语言模型生成更准确的回答。有时大语言模型的回复会有可靠性问题，例如真实性、偏差、校准、数学计算等等。这一章节会介绍提升大语言模型可靠性的技巧。

内容：
- [真实性（Factuality）]()
- [偏差（Biases）]()
- 校准
- 数学

## 真实性

大语言模型倾向于生成听上去连贯和可信的回答，为此，大语言模型有时会编造一些内容。提示词工程可以用来引导大语言模型生成更加真实的回复，避免胡编乱造。

这些方法可以有效改进回复的真实性：
- 提供真实的背景信息，例如维基百科的相关段落
- 举例子。询问大语言模型能答得上来的和答不上来的问题。对于那些答不上来的问题，提供的回答需要是引导大语言模型承认自己不知道（比如“我不知道”）。

### 例子

## 偏差

[上一章节（进阶篇）](prompting-advanced-techniques.md)

[下一章节（图像篇）](prompting-image-prompting.md)
